{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages \n",
    "import tensorflow as tf\n",
    "\n",
    "# Zip file reading \n",
    "import zipfile\n",
    "\n",
    "# Array math \n",
    "import numpy as np \n",
    "\n",
    "# Tensorflow text \n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "2.10.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Printing the version of tf, tf_text \n",
    "print(tf.__version__)\n",
    "print(tf_text.__version__)\n",
    "\n",
    "# Checking if GPU is available\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path to the data \n",
    "path_to_file = 'input/lit-eng.zip'\n",
    "\n",
    "# Loading the data\n",
    "archive = zipfile.ZipFile(path_to_file, 'r')\n",
    "text = archive.read('lit.txt').decode('utf-8')\n",
    "\n",
    "# Splitting the data into target and context\n",
    "lines = text.splitlines()\n",
    "pairs = [line.split('\\t') for line in lines]\n",
    "\n",
    "# Creating the context and the target data \n",
    "target_raw = np.array([x[0] for x in pairs])\n",
    "context_raw = np.array([x[1] for x in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of examples: 2140\n",
      "Target: Go on.\n",
      "Context: Tęsk.\n",
      "---\n",
      "Target: January, February, March, April, May, June, July, August, September, October, November and December are the twelve months of the year.\n",
      "Context: Metus sudaro dvylika mėnesių: sausis, vasaris, kovas, balandis, gegužė, birželis, liepa, rugpjūtis, rugsėjis, spalis, lapkritis ir gruodis.\n",
      "---\n",
      "Target: Before I get out of bed, I spend a little time thinking about what I'll be doing the rest of the day.\n",
      "Context: Prieš atsikeldamas iš lovos, aš praleidžiu kažkiek laiko galvodamas apie tai, ką veiksiu likusią dienos dalį.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Printing the amount of data we have\n",
    "print('Amount of examples:', len(target_raw))\n",
    "\n",
    "# Printing out some target and context data \n",
    "for i in range(3):\n",
    "    print('Target:', target_raw[-i])\n",
    "    print('Context:', context_raw[-i])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a TF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(context_raw)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))\n",
    "\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Ne\\xc5\\xbeaiskite su ugnimi.'\n",
      " b'Mes valgome, kad gyventume, o negyvename, kad valgytume.'\n",
      " b'Kartais svajon\\xc4\\x97s i\\xc5\\xa1sipildo.'\n",
      " b'De\\xc5\\xa1imt met\\xc5\\xb3 yra ilgas laikas.'\n",
      " b'\\xc5\\xa0unis yra i\\xc5\\xa1tikimi.' b'Ar tu nebuvai pavargusi?'\n",
      " b'Maniau, sakiai, kad jis tavo.' b'Kambaryje nieko n\\xc4\\x97ra.'], shape=(8,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b\"Don't play with fire.\" b'We eat to live, not live to eat.'\n",
      " b'Dreams sometimes come true.' b'Ten years is a long time.'\n",
      " b'Dogs are faithful.' b\"Weren't you tired?\"\n",
      " b'I thought you said it was yours.' b\"There's no one in the room.\"], shape=(8,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Showing one batch of the data \n",
    "for example_context_strings, example_target_strings in train_raw.take(1):\n",
    "  print(example_context_strings)\n",
    "  print()\n",
    "  print(example_target_strings)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text: str) -> str:\n",
    "  \"\"\"\n",
    "  Function that preprocesses the text by lowercasing it and splitting the\n",
    "    punctuation from the words.\n",
    "  \"\"\"\n",
    "  # The bellow line normalizes converts the text to NFKD form, which is a\n",
    "  #  compatibility decomposition form. This is done to ensure that the text\n",
    "  #  is in a standard form.\n",
    "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "  \n",
    "  # Lowercasing\n",
    "  text = tf.strings.lower(text)\n",
    "  \n",
    "  # Keep space, a to z, and select punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
    "  \n",
    "  # Add spaces around punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "  \n",
    "  # Strip whitespace.\n",
    "  text = tf.strings.strip(text)\n",
    "\n",
    "  # Add start and end tokens.\n",
    "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "  \n",
    "  # Returning \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'[START] lietuviskas tekstas [END]', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Showing an example \n",
    "example_text = 'Lietuviškas tekstas'\n",
    "print(tf_lower_and_split_punct(example_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the maximum number of unqiue words that we will extract from the context data\n",
    "max_vocab_size = 10000\n",
    "\n",
    "# A layer which will vectorizes the text\n",
    "context_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'as', ',', '?', 'tomas', 'tai']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The adapt() function is similar to model.fit() function in that it will\n",
    "#  train the layer on the data that we pass to it.\n",
    "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
    "\n",
    "# Here are the first 20 words from the vocabulary:\n",
    "context_text_processor.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'i', 'the', 'you', 'to', '?']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets build the target text processor\n",
    "target_text_processor = tf.keras.layers.TextVectorization(\n",
    "    standardize=tf_lower_and_split_punct,\n",
    "    max_tokens=max_vocab_size,\n",
    "    ragged=True)\n",
    "\n",
    "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
    "target_text_processor.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'Ne\\xc5\\xbeaiskite su ugnimi.'\n",
      " b'Mes valgome, kad gyventume, o negyvename, kad valgytume.'\n",
      " b'Kartais svajon\\xc4\\x97s i\\xc5\\xa1sipildo.'\n",
      " b'De\\xc5\\xa1imt met\\xc5\\xb3 yra ilgas laikas.'\n",
      " b'\\xc5\\xa0unis yra i\\xc5\\xa1tikimi.' b'Ar tu nebuvai pavargusi?'\n",
      " b'Maniau, sakiai, kad jis tavo.' b'Kambaryje nieko n\\xc4\\x97ra.']\n"
     ]
    }
   ],
   "source": [
    "# Printing out once again the first batch of the context strings\n",
    "print(example_context_strings.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[2, 1714, 22, 308, 4, 3],\n",
       " [2, 23, 975, 6, 14, 2258, 6, 363, 1830, 6, 14, 972, 4, 3],\n",
       " [2, 276, 1128, 2178, 4, 3], [2, 806, 111, 11, 2237, 216, 4, 3],\n",
       " [2, 1168, 11, 2169, 4, 3], [2, 10, 13, 663, 202, 7, 3],\n",
       " [2, 214, 6, 556, 6, 14, 12, 38, 4, 3], [2, 181, 46, 39, 4, 3]]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The context text processor will convert the context strings into tokens\n",
    "example_tokens = context_text_processor(example_context_strings)\n",
    "example_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(context: str, target: str):\n",
    "  \"\"\"\n",
    "  Function that creates the input and output for the deep learning model; \n",
    "\n",
    "    Args:\n",
    "        context: The context data\n",
    "        target: The target data\n",
    "\n",
    "    Returns:\n",
    "        A tuple of the input and output data\n",
    "  \"\"\"\n",
    "  # Preprocesing and tokenizing the raw input text\n",
    "  context = context_text_processor(context).to_tensor()\n",
    "  target = target_text_processor(target)\n",
    "\n",
    "  # Creating the input and output data for deep learning\n",
    "  targ_in = target[:,:-1].to_tensor()\n",
    "  targ_out = target[:,1:].to_tensor()\n",
    "\n",
    "  # Returning\n",
    "  return (context, targ_in), targ_out\n",
    "\n",
    "# Applying the function to the list of texts \n",
    "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
    "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an example context and target sentences \n",
    "example_context = \"Labas pasauli!\"\n",
    "example_target = \"Hello world!\"\n",
    "\n",
    "# Applying the function to the example context and target sentences\n",
    "(context_tokens, target_tokens), target_tokens_out = process_text([example_context], [example_target])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `process_text()` function is a tuple consisting of ((context tokens $X$, target tokens $X$), target tokens $Y$). \n",
    "\n",
    "The $Y$ tokens is a sequence of tokens that are shifted by one unit to the right of the $X$ tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context tokens X: [[   2 2018  352   36    3]]\n",
      "The target tokens X: [[   2 1281  148   78]]\n",
      "The target tokens y: [[1281  148   78    3]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The context tokens X: {context_tokens.numpy()}\")\n",
    "print(f\"The target tokens X: {target_tokens.numpy()}\")\n",
    "print(f\"The target tokens y: {target_tokens_out.numpy()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The encoder "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the encoder is to process the context sequence into a sequence of vectors that are useful for the decoder as it attempts to predict the next output for each timestep. \n",
    "\n",
    "We will use a bidirectional-RNN to do the processing.\n",
    "\n",
    "The encoder:\n",
    "\n",
    "* Takes a list of token IDs (from context_text_processor).\n",
    "* Looks up an embedding vector for each token (Using a layers.Embedding).\n",
    "* Processes the embeddings into a new sequence (Using a bidirectional layers.GRU).\n",
    "* Returns the processed sequence. This will be passed to the attention head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the UNITS for the RNN layer; \n",
    "UNITS = 128\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, text_processor, units):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = text_processor.vocabulary_size()\n",
    "    self.units = units\n",
    "\n",
    "    # The embedding layer converts tokens to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(\n",
    "        self.vocab_size, \n",
    "        units,\n",
    "        mask_zero=True)\n",
    "\n",
    "    # The RNN layer processes those vectors sequentially.\n",
    "    self.rnn = tf.keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=tf.keras.layers.GRU(units,\n",
    "                            # Return the sequence and state\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "  def call(self, x):\n",
    "    \n",
    "    # 1. The embedding layer looks up the embedding vector for each token.\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # 3. The GRU processes the sequence of embeddings.\n",
    "    x = self.rnn(x)\n",
    "\n",
    "    # 4. Returns the new sequence of embeddings.\n",
    "    return x\n",
    "\n",
    "  def convert_input(self, texts):\n",
    "    texts = tf.convert_to_tensor(texts)\n",
    "    if len(texts.shape) == 0:\n",
    "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "    context = self.text_processor(texts).to_tensor()\n",
    "    context = self(context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting an example number of embedding dimensions \n",
    "embedding_dim_example = 10\n",
    "\n",
    "# Initiating the encoder \n",
    "encoder_example = Encoder(context_text_processor, embedding_dim_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have the original context string:\n",
      "'Vandeniu, žeme ir oru!'\n",
      "Its token form is:\n",
      "[[   2  969    6    1   21 1646   36    3]]\n",
      "The first layer for the encoder is the embedding layer, which converts the tokens to vectors. The shape of the output: (1, 8, 10)\n",
      "Embedding output:\n",
      "[[[ 0.04450219 -0.03834212  0.02642426  0.0076616   0.01130848\n",
      "    0.02561903 -0.03648316  0.02317765  0.03023699 -0.01628438]\n",
      "  [-0.02516098 -0.02166842  0.02130898 -0.00571905 -0.04905744\n",
      "   -0.00580677 -0.03810577 -0.02370191  0.0434409  -0.0301008 ]\n",
      "  [-0.03928101  0.00330967  0.0049296   0.00819153  0.01588798\n",
      "    0.00770397  0.04836607  0.0289692   0.03934513 -0.02607347]\n",
      "  [ 0.0244338   0.00356202  0.02282291 -0.00224922  0.03450264\n",
      "   -0.01853289 -0.03045956  0.01710209  0.02187247 -0.00715552]\n",
      "  [ 0.01397747 -0.0084367  -0.02343072  0.03459773  0.04115411\n",
      "    0.03225381  0.03548944 -0.01587107  0.00378732 -0.02506669]\n",
      "  [ 0.02397806 -0.03537195 -0.03064996 -0.00405379 -0.03447749\n",
      "    0.01471053  0.00835864  0.04873339  0.01286561 -0.01216229]\n",
      "  [-0.04416547 -0.03587428 -0.0244612   0.00256949 -0.02737753\n",
      "   -0.03707415  0.01459371  0.00704938 -0.02798909 -0.03632475]\n",
      "  [ 0.04882704 -0.01019245 -0.04282624  0.00074571  0.04541571\n",
      "    0.03675037 -0.00118556  0.02252611 -0.03653659 -0.02768287]]]\n"
     ]
    }
   ],
   "source": [
    "# Defining the example sentence \n",
    "example_context = \"Vandeniu, žeme ir oru!\"\n",
    "example_target = \"By sea, land and air!\"\n",
    "\n",
    "# Applying the function to the example context and target sentences\n",
    "(context_tokens, target_tokens), target_tokens_out = process_text([example_context], [example_target])\n",
    "\n",
    "print(f\"We have the original context string:\\n'{example_context}'\") \n",
    "print(f\"Its token form is:\\n{context_tokens.numpy()}\")\n",
    "embedding_output = encoder_example.embedding(context_tokens)\n",
    "print(f\"The first layer for the encoder is the embedding layer, which converts the tokens to vectors. The shape of the output: {embedding_output.shape}\")\n",
    "print(f\"Embedding output:\\n{embedding_output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above code, the first layer in the encoder takes the tokens and assigns them a vector of size 10 (example constant). The output shape is (batch_size, sequence_length, embedding_dimension). In our case:\n",
    "* batch_size = 1, because we provided one sentence\n",
    "* sequence_length = 8, because we provided 8 tokens \n",
    "* embedding_dimension = 10, because we provided 10 as the embedding dimension \n",
    "\n",
    "The output of the embedding layer gets fed into the bidirectional GRU layer. \n",
    "\n",
    "`GRU` stands for Gated Recurrent Unit. It is a type of RNN that is able to learn long-term dependencies. \n",
    "\n",
    "The generic input shape for the GRU layer is **(batch_size, sequence_length, number of features)**. \n",
    "\n",
    "In our case, the batch size is 1, the sequence length is 8 and the number of features is 10. Each number in the embedding vector is a feature.\n",
    "\n",
    "Because we have set the `return_sequences` parameter to `True`, the output of the GRU layer is a sequence of vectors. \n",
    "\n",
    "The output shape is (batch_size, sequence_length, embedding_dimension).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the RNN output: (1, 8, 10)\n",
      "RNN output:\n",
      "[[[ 0.01882152  0.00135372 -0.01662301  0.02526054 -0.00643379\n",
      "    0.01713916  0.0149806  -0.000564   -0.00476052  0.0244658 ]\n",
      "  [ 0.02813361 -0.0112968   0.0052719  -0.01278985  0.0059546\n",
      "    0.00366347  0.00330911  0.00188386  0.00457937  0.03087011]\n",
      "  [ 0.03105481 -0.00715557 -0.00376149  0.01787064 -0.01643648\n",
      "    0.00280224  0.00844893  0.00859217 -0.00913633  0.00964303]\n",
      "  [ 0.01832861  0.00136256 -0.03106287  0.03231924 -0.01670991\n",
      "    0.01064127  0.01257971 -0.00684161 -0.01363955  0.01880245]\n",
      "  [ 0.01451444  0.01780497 -0.01984466  0.02564278 -0.02929392\n",
      "    0.01237199  0.00675356  0.00760588 -0.01046836 -0.01500607]\n",
      "  [ 0.01690835  0.00991304 -0.01740106  0.0046435  -0.01482428\n",
      "    0.00835882  0.02395185  0.00653472  0.00056449 -0.01246439]\n",
      "  [ 0.00238482  0.00980644 -0.00530771 -0.01611545 -0.00972703\n",
      "   -0.0093706   0.01469161  0.00346752 -0.00792204 -0.02686535]\n",
      "  [-0.00663948  0.02494486 -0.03550029  0.02347191 -0.02654553\n",
      "    0.00141859  0.01795219 -0.00631441 -0.01399451 -0.01786034]]]\n"
     ]
    }
   ],
   "source": [
    "# We pass the output of the embedding layer to the RNN layer\n",
    "rnn_output = encoder_example.rnn(embedding_output)\n",
    "\n",
    "print(f\"The shape of the RNN output: {rnn_output.shape}\")\n",
    "print(f\"RNN output:\\n{rnn_output}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output is the encoder output. It is a sequence of vectors that are useful for the decoder as it attempts to predict the next output for each timestep. \n",
    "\n",
    "# Attention layer \n",
    "\n",
    "The attention layer is a mechanism that allows the decoder to focus on the relevant parts of the encoder output. \n",
    "\n",
    "The simplest way you could calculate a single vector from the entire sequence would be to take the average across the sequence (`layers.GlobalAveragePooling1D`). An attention layer is similar, but calculates a weighted average across the context sequence. Where the weights are calculated from the combination of context and \"query\" vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "class SelfAttentionLayer(layers.Layer):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.query_layer = layers.Dense(embedding_dim)\n",
    "        self.key_layer = layers.Dense(embedding_dim)\n",
    "        self.value_layer = layers.Dense(embedding_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Compute query, key, and value matrices\n",
    "        query = self.query_layer(inputs)\n",
    "        key = self.key_layer(inputs)\n",
    "        value = self.value_layer(inputs)\n",
    "        \n",
    "        # Compute dot product attention scores\n",
    "        scores = tf.matmul(query, key, transpose_b=True)\n",
    "        scores_scaled = tf.divide(scores, tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32)))\n",
    "        attention_weights = tf.nn.softmax(scores_scaled, axis=-1)\n",
    "        \n",
    "        # Apply attention weights to value matrix\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query matrix:\n",
      "[[[-0.00839226 -0.01421904  0.01949998 -0.01202205  0.01488757\n",
      "    0.01198664 -0.00209417 -0.0094746  -0.00261967  0.02356385]\n",
      "  [-0.00425759 -0.01746158 -0.02190064 -0.00700978  0.00342614\n",
      "   -0.02015614  0.00848745 -0.02948325  0.00479916 -0.00192907]\n",
      "  [-0.01243407 -0.01030727 -0.00065965 -0.00720427  0.00798002\n",
      "   -0.00632861  0.01057748 -0.01312093 -0.02157345  0.00170836]\n",
      "  [-0.021781   -0.0167504   0.03156691 -0.02483669  0.01643346\n",
      "    0.02221419 -0.00274086 -0.00090497 -0.00038572  0.02773965]\n",
      "  [-0.01552628  0.00855328  0.02616021 -0.003216    0.00101429\n",
      "    0.01657802  0.01138128  0.02170641 -0.02607228  0.006862  ]\n",
      "  [-0.02364073 -0.00302263  0.01336624 -0.0033468  -0.00401209\n",
      "   -0.0109858   0.01350125  0.00971766 -0.02404812 -0.01200932]\n",
      "  [-0.02698657  0.00385442  0.0005471  -0.00640507 -0.02308033\n",
      "   -0.01895544  0.01214225  0.01451633 -0.01991589 -0.02591465]\n",
      "  [-0.03149271  0.00304063  0.04571516 -0.02218417 -0.00511967\n",
      "    0.02515347 -0.00211561  0.03342501 -0.0125676   0.01016246]]]\n",
      "Key matrix:\n",
      "[[[-1.10481391e-02  8.35003890e-03 -2.42558289e-02  4.10285499e-03\n",
      "   -1.99982766e-02 -3.15611735e-02  2.87574753e-02 -1.02894865e-02\n",
      "   -2.07450967e-02  4.77963267e-03]\n",
      "  [-3.61593906e-03  2.59224791e-04 -1.05322655e-02  2.64097638e-02\n",
      "   -1.03310896e-02  6.79937564e-03  3.26441019e-03 -7.97850918e-03\n",
      "   -1.79440621e-02  1.73011795e-04]\n",
      "  [-1.93801709e-04  7.11120805e-03 -1.11348573e-02  1.10087218e-03\n",
      "   -2.32635513e-02 -1.69143733e-02  1.00100888e-02  1.43825915e-02\n",
      "   -1.61514450e-02  1.13295568e-02]\n",
      "  [-1.41277472e-02  9.86520387e-03 -2.20270045e-02 -5.12134284e-05\n",
      "   -1.41271446e-02 -4.80863228e-02  3.52480523e-02 -5.50697604e-03\n",
      "   -1.81360878e-02  8.60722177e-03]\n",
      "  [ 7.64812529e-03  1.15508027e-02 -5.85372001e-03 -1.57278776e-02\n",
      "   -1.44963544e-02 -3.41689363e-02  2.36736722e-02  1.59464777e-02\n",
      "    1.80546660e-03  2.64761038e-05]\n",
      "  [ 6.15292042e-03 -4.98053385e-03 -8.63626413e-03 -6.95960782e-03\n",
      "    3.68334050e-03 -1.84308123e-02  2.13809665e-02  5.23803756e-04\n",
      "   -4.41873586e-03  8.11299402e-03]\n",
      "  [ 1.72877852e-02 -8.94886255e-03  1.50292544e-02 -1.49763003e-03\n",
      "    2.21965723e-02 -3.37871071e-03  3.83777730e-03  7.40530435e-03\n",
      "    2.08108500e-03  9.10783466e-03]\n",
      "  [-2.40374822e-03  4.48727887e-03 -3.17016710e-03 -1.55342426e-02\n",
      "    9.97474231e-03 -5.17255738e-02  3.38261873e-02 -2.30231136e-03\n",
      "   -1.05372537e-03  4.66959085e-03]]]\n",
      "Value matrix:\n",
      "[[[-0.03134394  0.01693948  0.01307922 -0.00435589 -0.00106687\n",
      "   -0.00427749  0.01599692 -0.01318014 -0.02477607  0.00126688]\n",
      "  [ 0.00065712  0.00638875  0.00096939 -0.00242815  0.00154368\n",
      "   -0.01946075 -0.00033857 -0.01348699 -0.00619884  0.00674269]\n",
      "  [-0.02258489  0.0030299   0.00276698 -0.01200255 -0.01455675\n",
      "   -0.00858672  0.00800678  0.00738627 -0.00473702 -0.00126211]\n",
      "  [-0.03177015  0.0098229   0.01491465  0.00124834  0.00088724\n",
      "   -0.00208946  0.02021514 -0.0045406  -0.03070978  0.00151118]\n",
      "  [-0.04010363  0.00146103 -0.00617704 -0.00219858 -0.00324291\n",
      "    0.01350138  0.01341477  0.02305035 -0.00228439 -0.01132375]\n",
      "  [-0.02752019  0.00727368 -0.00277219  0.01262867  0.00794185\n",
      "    0.00583629  0.00281641  0.00531135 -0.0089787  -0.00317807]\n",
      "  [ 0.00541408 -0.00241169 -0.0144567   0.01816247  0.00997825\n",
      "    0.00958771 -0.00852872  0.01749158  0.00076406 -0.00564434]\n",
      "  [-0.02799153  0.00394798 -0.00193173  0.02419789  0.01977944\n",
      "    0.02011144  0.01505871  0.01521051 -0.02028583 -0.00418504]]]\n",
      "Query matrix shape: (1, 8, 10)\n",
      "Key matrix shape: (1, 8, 10)\n",
      "Value matrix shape: (1, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "# We have an embedding size of **embedding_dim_example** \n",
    "attention_example = SelfAttentionLayer(embedding_dim_example)\n",
    "\n",
    "# Calculating the query, key and value matrices\n",
    "query = attention_example.query_layer(rnn_output)\n",
    "key = attention_example.key_layer(rnn_output)\n",
    "value = attention_example.value_layer(rnn_output)\n",
    "\n",
    "# Printing out the query, key and value matrices\n",
    "print(f\"Query matrix:\\n{query}\")\n",
    "print(f\"Key matrix:\\n{key}\")\n",
    "print(f\"Value matrix:\\n{value}\")\n",
    "\n",
    "# Printing out the shapes\n",
    "print(f\"Query matrix shape: {query.shape}\")\n",
    "print(f\"Key matrix shape: {key.shape}\")\n",
    "print(f\"Value matrix shape: {value.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above matrices have an output of shape (batch_size, sequence_length, embedding_dimension). \n",
    "\n",
    "Each vector that gets fed into any of the underlying Dense layers is a vector of size 10. Thus, each query, key and value layer is just a dense layer with 10 neurons each.\n",
    "\n",
    "The first computation is the dot product of the query and key vectors. We multiply the query vector with the key vector because we want to know how much the query vector is related to the key vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product attention scores:\n",
      "[[[-1.0201239e-03 -4.4868028e-04 -7.2688924e-04 -1.0086417e-03\n",
      "   -9.8364765e-04 -7.8633369e-05  7.1415375e-04 -3.2644288e-04]\n",
      "  [ 1.4099921e-03  6.0449453e-05 -6.4434033e-05  1.6493733e-03\n",
      "    3.8262733e-04  8.1197970e-04 -2.8518657e-04  1.5278750e-03]\n",
      "  [ 9.7279914e-04  2.6012617e-04  1.3489346e-04  1.1315203e-03\n",
      "    5.8455007e-06  5.0517143e-04 -9.2395276e-06  9.2330459e-04]\n",
      "  [-1.7254781e-03 -9.2272466e-04 -9.7171345e-04 -1.6978084e-03\n",
      "   -1.2307597e-03 -3.3157325e-04  8.0931140e-04 -6.8287319e-04]\n",
      "  [-2.7066271e-04  1.3313891e-04  3.8997037e-04 -2.7029717e-04\n",
      "   -1.3497373e-04 -2.1789613e-04  2.3218978e-04 -4.1013624e-04]\n",
      "  [ 1.0547187e-03  2.1827198e-04  6.3699041e-04  1.3500205e-03\n",
      "    6.2305923e-04  2.6774278e-04 -2.6333498e-04  9.8469132e-04]\n",
      "  [ 1.8397184e-03  3.0992916e-04  1.2354427e-03  2.1313103e-03\n",
      "    1.4002207e-03  2.6393426e-04 -1.0548511e-03  1.2074687e-03]\n",
      "  [-1.6135173e-03 -7.7509502e-04 -3.4399207e-05 -1.6113701e-03\n",
      "   -4.4917737e-04 -8.2153239e-04  2.5582037e-04 -1.1509312e-03]]]\n",
      "Shape of scores: (1, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "scores = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "print(f\"Dot product attention scores:\\n{scores}\")\n",
    "print(f\"Shape of scores: {scores.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shape is now (batch_size, sequence_length, sequence_length).  \n",
    "\n",
    "The next step will be is to normalize the values in the matrix. We do this by dividing each value by the square root of the embedding dimension. After that, we apply the softmax function to the matrix. \n",
    "\n",
    "After applying the softmax function, we get a matrix of values that sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights:\n",
      "[[[0.12497884 0.12500143 0.12499043 0.12497929 0.12498028 0.12501605\n",
      "   0.1250474  0.12500626]\n",
      "  [0.1250286  0.12497525 0.12497031 0.12503806 0.12498798 0.12500495\n",
      "   0.12496158 0.12503326]\n",
      "  [0.12501906 0.1249909  0.12498595 0.12502533 0.12498084 0.12500058\n",
      "   0.12498024 0.1250171 ]\n",
      "  [0.12496518 0.12499689 0.12499496 0.12496626 0.12498472 0.12502027\n",
      "   0.12506537 0.12500638]\n",
      "  [0.12499201 0.12500797 0.12501812 0.12499203 0.12499738 0.12499409\n",
      "   0.12501189 0.1249865 ]\n",
      "  [0.12501761 0.12498455 0.1250011  0.12502928 0.12500055 0.12498651\n",
      "   0.12496551 0.12501486]\n",
      "  [0.1250365  0.12497602 0.12501259 0.12504801 0.1250191  0.1249742\n",
      "   0.12492209 0.12501149]\n",
      "  [0.12496687 0.12499999 0.12502928 0.12496695 0.12501289 0.12499817\n",
      "   0.12504075 0.12498514]]]\n"
     ]
    }
   ],
   "source": [
    "# Scaling the scores\n",
    "scores_scaled = tf.divide(scores, tf.math.sqrt(tf.cast(embedding_dim_example, tf.float32)))\n",
    "\n",
    "# Applying the softmax function\n",
    "attention_weights = tf.nn.softmax(scores_scaled, axis=-1)\n",
    "\n",
    "print(f\"Attention weights:\\n{attention_weights}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step of the attention layer is to multiply the normalized matrix with the value matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "[[[-0.02190342  0.00580592  0.00079784  0.00440796  0.00265892\n",
      "    0.0018284   0.00832882  0.00465613 -0.01214981 -0.00200923]\n",
      "  [-0.02190764  0.00580736  0.00080046  0.00440706  0.00265874\n",
      "    0.0018285   0.00833186  0.00465444 -0.01215313 -0.00200891]\n",
      "  [-0.02190632  0.00580707  0.00080002  0.00440677  0.00265839\n",
      "    0.00182786  0.00833106  0.00465442 -0.01215227 -0.0020088 ]\n",
      "  [-0.02190289  0.00580554  0.00079718  0.00440833  0.00265905\n",
      "    0.00182879  0.00832829  0.0046569  -0.01214911 -0.00200947]\n",
      "  [-0.02190458  0.00580627  0.00079879  0.00440613  0.00265755\n",
      "    0.00182731  0.00832968  0.00465537 -0.01215017 -0.00200903]\n",
      "  [-0.02190716  0.00580704  0.00080023  0.00440607  0.0026578\n",
      "    0.00182785  0.00833156  0.00465471 -0.01215227 -0.00200894]\n",
      "  [-0.02190916  0.00580755  0.00080134  0.00440483  0.00265696\n",
      "    0.00182749  0.00833286  0.00465412 -0.01215321 -0.00200887]\n",
      "  [-0.02190379  0.00580555  0.00079759  0.00440661  0.00265763\n",
      "    0.00182801  0.00832881  0.00465687 -0.0121488  -0.00200951]]]\n",
      "Shape of output: (1, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "# Multiplying the attention weights with the value matrix\n",
    "output = tf.matmul(attention_weights, value)\n",
    "\n",
    "print(f\"Output:\\n{output}\")\n",
    "print(f\"Shape of output: {output.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is the exact same shape as the input. The attention layer returns a weighted average of the context vectors. Thus, we can infer which positions in the context sequence are more important than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
